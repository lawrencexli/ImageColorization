{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce7b875f-a93d-4d8c-add1-e4ccfb8dcc16",
   "metadata": {},
   "source": [
    "# Image Colorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2909ee-a7c8-4301-b8eb-253e087d5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import *\n",
    "import torchvision\n",
    "from torchmetrics.functional import peak_signal_noise_ratio\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from dataset import *\n",
    "from model import *\n",
    "import pickle \n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b489f-ae2a-464c-b0b8-cd8eeada4cd2",
   "metadata": {},
   "source": [
    "## Read and build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062626c-2338-4652-b90d-3586c7f6f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 256\n",
    "mirflickr = Mirflickr('custom_image')\n",
    "train_dataloader, eval_dataloader = mirflickr.build_dataset(size=size, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f35c7de-e8e5-41f4-9beb-19bf342e3a1c",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f98b5-3ab4-4077-b44b-431b5146f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MainModel(size=size, pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f08f4-c942-4c7f-bc7a-ea66557620da",
   "metadata": {},
   "source": [
    "### Define accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4683d4-93a9-42dd-90fa-5275934c31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ssim(true, result, is_train=False):\n",
    "    if is_train:\n",
    "        true = true.detach().cpu().numpy()\n",
    "        result = result.detach().cpu().numpy()\n",
    "        \n",
    "        a = ssim(true[:, 0, :, :], result[:, 0, :, :], data_range=true.max() - true.min())\n",
    "        b = ssim(true[:, 1, :, :], result[:, 1, :, :], data_range=true.max() - true.min())\n",
    "    else:\n",
    "        true = true.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
    "        result = result.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
    "        \n",
    "        a = ssim(true[:, :, 0], result[:, :, 0], data_range=true.max() - true.min())\n",
    "        b = ssim(true[:, :, 1], result[:, :, 1], data_range=true.max() - true.min())\n",
    "        \n",
    "    return (a + b) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da5a09-2bd4-474a-b44b-1b3e2aaefc28",
   "metadata": {},
   "source": [
    "## Load model and visualize the result\n",
    "## Also with SSIM, PSNR, and L1 loss evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a2fc5-3dda-47c6-9b7a-d75e4515cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = torch.load(\"saved_weights/unet_GAN_25k\", map_location=model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9a833-f787-4122-96bd-4532e01ea000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(img_norm):\n",
    "    img_norm[:, :, 0] = (img_norm[:, :, 0] + 1.) * 50.\n",
    "    img_norm[:, :, 1] = ifunc(img_norm[:, :, 1])\n",
    "    img_norm[:, :, 2] = ifunc(img_norm[:, :, 2])\n",
    "    return img_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4335b9-94c9-42ca-a21d-419c317f5000",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in eval_dataloader: # or train_dataloader\n",
    "    L = data['L'].to(model.device)\n",
    "    ab = data['ab'].to(model.device)\n",
    "    \n",
    "    # If using train_dataloader, it has a batch size of 16, so just choose the first image batch to visualize\n",
    "    if len(L) != 1 and len(ab) != 1:\n",
    "        L = L[0, :, :, :].unsqueeze(0)\n",
    "        ab = ab[0, :, :, :].unsqueeze(0)\n",
    "    break\n",
    "    \n",
    "ab_zero = torch.tensor(0).expand_as(ab).float().to(model.device)\n",
    "raw_input_image = torch.cat([L, ab_zero], dim=1)\n",
    "\n",
    "input_image = raw_input_image.squeeze(0).permute(1, 2, 0)\n",
    "input_image = input_image.detach().cpu().numpy()\n",
    "input_ = lab2rgb(denormalize(input_image)) \n",
    "\n",
    "raw_true_image = torch.cat([L, ab], dim=1)\n",
    "true_image = raw_true_image.squeeze(0).permute(1, 2, 0)\n",
    "true_image = true_image.detach().cpu().numpy()\n",
    "true = lab2rgb(denormalize(true_image)) \n",
    "\n",
    "colorized_result = model_result(L)\n",
    "raw_colorized_image = torch.cat([L, colorized_result], dim=1)\n",
    "colorized_image = raw_colorized_image.squeeze(0).permute(1, 2, 0)\n",
    "colorized_image = colorized_image.detach().cpu().numpy()\n",
    "result = lab2rgb(denormalize(colorized_image)) \n",
    "\n",
    "f, axarr = plt.subplots(1, 2, figsize=(10, 10))\n",
    "axarr[0].imshow(input_)\n",
    "axarr[1].imshow(result)\n",
    "axarr[0].axis('off') \n",
    "axarr[1].axis('off') \n",
    "\n",
    "plt.savefig('result.png', transparent=True, bbox_inches='tight')\n",
    "\n",
    "# Use PSNR metrics to evaluate the performance\n",
    "# The range of PSNR score is [-inf, +inf]\n",
    "# +inf means that they are identical\n",
    "# -inf means that they are completely different (100% black and white image versus true colors)\n",
    "print('PSNR score: %.4f' % (peak_signal_noise_ratio(ab, colorized_result)))\n",
    "\n",
    "# SSIM compares the perceived quality between 2 images\n",
    "# The range of SSIM is [-1, 1]\n",
    "# Lower means very poor result\n",
    "# Higher means excellent result\n",
    "# -1: Anti-correlated\n",
    "# 0: No similarity\n",
    "# 1: Identical\n",
    "print('SSIM score: %.4f' % (compute_ssim(ab, colorized_result)))\n",
    "\n",
    "# Print the evaluation l1 loss\n",
    "print('Evaluation L1 loss: %.4f' % (model.GLoss(ab, colorized_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb36a1-8782-429b-b642-a5f9324e1e0f",
   "metadata": {},
   "source": [
    "## Perform evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b3bef-f1e8-43cf-88f6-a3ea1c7c5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "PSNR = []\n",
    "SSIM = []\n",
    "L1_Loss = []\n",
    "\n",
    "for data in eval_dataloader:\n",
    "    L = data['L'].to(model.device)\n",
    "    ab = data['ab'].to(model.device)\n",
    "    \n",
    "    ab_zero = torch.tensor(0).expand_as(ab).float().to(model.device)\n",
    "    raw_input_image = torch.cat([L, ab_zero], dim=1)\n",
    "    input_image = raw_input_image.squeeze(0).permute(1, 2, 0)\n",
    "    input_image = input_image.detach().cpu().numpy()\n",
    "    input_ = lab2rgb(denormalize(input_image)) \n",
    "\n",
    "    raw_true_image = torch.cat([L, ab], dim=1)\n",
    "    true_image = raw_true_image.squeeze(0).permute(1, 2, 0)\n",
    "    true_image = true_image.detach().cpu().numpy()\n",
    "    true = lab2rgb(denormalize(true_image)) \n",
    "\n",
    "    colorized_result = model_result(L)\n",
    "    raw_colorized_image = torch.cat([L, colorized_result], dim=1)\n",
    "    colorized_image = raw_colorized_image.squeeze(0).permute(1, 2, 0)\n",
    "    colorized_image = colorized_image.detach().cpu().numpy()\n",
    "    result = lab2rgb(denormalize(colorized_image)) \n",
    "    \n",
    "\n",
    "    PSNR.append(float(peak_signal_noise_ratio(ab, colorized_result)))\n",
    "    SSIM.append(float(compute_ssim(ab, colorized_result)))\n",
    "    L1_Loss.append(float(model.GLoss(ab, colorized_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb746d-c988-4466-b3cf-51aa18002d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(l):\n",
    "    total = 0\n",
    "    for i in l:\n",
    "        total += i\n",
    "    return total / len(l)\n",
    "\n",
    "print(\"Evaluation performance:\")\n",
    "avg(PSNR), avg(SSIM), avg(L1_Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a2677-53cd-437a-b5c5-4ebb69981713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m106",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m106"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
